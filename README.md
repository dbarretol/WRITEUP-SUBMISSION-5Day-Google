# AIDA: Academic Ideation & Drafting Assistant

> **Note:** This project was inspired by the [academic_research](https://github.com/google/adk-samples/tree/main/python/agents/academic-research) sample from the [Google ADK Samples](https://github.com/google/adk-samples) repository. While the structure served as a starting point, this implementation uses a custom Orchestrator pattern, strict Pydantic enforcement, and an enhanced PDF generation pipeline.

## Overview

**AIDA** is a sophisticated **multi-agent AI system** designed to accelerate the early stages of academic research. It leverages Google's **Gemini 2.0** models and the **Agent Development Kit (ADK)** to orchestrate a team of specialized AI agents.

Unlike simple chatbots, AIDA operates as a rigid pipeline with validation loops. It doesn't just "chat"‚Äîit interviews you, searches for real literature, formulates a problem, and rigorously validates its own plan before generating a professional PDF proposal.

The workflow consists of 6 distinct stages:
1.  **Interview**: Interactive requirement gathering (State Machine).
2.  **Problem Formulation**: AI-powered literature review via Google Search.
3.  **Objectives**: Generation of SMART objectives (Specific, Measurable, Achievable, Relevant, Time-bound).
4.  **Methodology**: Context-aware selection of qualitative/quantitative methods.
5.  **Data Collection**: Operational planning (Tools, Sample Size, Timeline).
6.  **Quality Control**: Automatic scoring and feedback loops for refinement.

> Check [Problem-Solution fit of AIDA](https://github.com/dbarretol/WRITEUP-SUBMISSION-5Day-Google/blob/main/docs/WRITE-UP.md)

## üéØ Key Features

| Feature | Description |
|---------|-------------|
| **Multi-Agent Orchestration** | 6 specialized agents coordinated by a central Finite State Machine. |
| **Real Literature Search** | The *Problem Formulation* agent uses Google Search to find and cite real papers (no hallucinated URLs). |
| **Auto-Refinement Loops** | If the *Quality Control* agent detects logical gaps, it sends the proposal back for revision automatically. |
| **Strict Type Safety** | All agent communication is validated against strict Pydantic schemas. |
| **PDF Reporting** | Generates a professional PDF proposal with hyperlinks and structured formatting. |
| **Dual-Mode Deployment** | Supports both standard **Gemini API** (API Key) and **Vertex AI** (Enterprise). |



## üìã Table of Contents

- [Quick Start](#quick-start)
- [System Architecture](#system-architecture)
- [Running the System](#running-the-system)
- [Project Structure](#project-structure)
- [Testing & Evaluation](#testing--evaluation)
- [Documentation](#documentation)



## Quick Start

### Prerequisites

- **Python 3.10+**
- **[uv](https://docs.astral.sh/uv/)** (recommended) or `pip`
- **Credentials**: A Google Cloud Project or a Gemini API Key.

### Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd FINAL-PROJECT

# Install dependencies
uv sync
# OR with pip: pip install -r requirements.txt
```

### Configuration

Create a `.env` file in the project root to configure the engine:

```bash
# --- OPTION 1: Standard Gemini API (Easiest) ---
GOOGLE_GENAI_USE_VERTEXAI=False
GOOGLE_API_KEY=your_api_key_here

# --- OPTION 2: Vertex AI (Enterprise) ---
GOOGLE_GENAI_USE_VERTEXAI=True
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_LOCATION=us-central1
```



## Running the System

You can interact with AIDA in three ways:

### 1. üñ•Ô∏è Interactive CLI Demo (Recommended)
Experience the full flow in your terminal, starting with an interactive interview and ending with a generated PDF.

```bash
python run_interactive_demo.py
```

### 2. üåê Web Interface (Streamlit)
A user-friendly web application with real-time progress tracking.

```bash
# Run the app
streamlit run app.py
```
*Access the dashboard at `http://localhost:8501`*

### 3. ‚ö° Individual Agent Demos
Test specific components in isolation (useful for debugging prompt logic).

```bash
# Test just the Problem Formulation agent (calls Google Search)
python demos/demo_problem_formulation.py

# Run the full orchestrator with mocked user input
python demos/demo_orchestrator.py
```



## System Architecture

<img src="academic-research.svg" alt="academic researcher architecture" width="500"/>

The system uses the **Orchestrator Pattern**:

*   **[Orchestrator](aida/orchestrator.py)**:  The brain. It manages the `WorkflowState`, executes agents, handles JSON parsing errors via regex, and manages the refinement loop.
*   **[Agents](aida/sub_agents/)**: Specialized modules. Most are pure LLM prompts, but `ProblemFormulation` has tool access (`google_search`).
*   **[Data Models](aida/data_models.py)**: Contains the strict Pydantic schemas that define the application's data model contracts..
*   **[WorkflowState](aida/workflow_state.py)**: The state manager. finit state machine definition.

*See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for the deep dive.*



## Project Structure

```text
FINAL-PROJECT/
‚îú‚îÄ‚îÄ aida/                           # Core Python Package
‚îÇ   ‚îú‚îÄ‚îÄ sub_agents/                 # Specialized Agents (The "Brains")
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_collection/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interviewer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ literature_review/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ methodology/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ objectives/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ problem_formulation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quality_control/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Env setup (Vertex vs Gemini)
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Global Config & Retry Logic
‚îÇ   ‚îú‚îÄ‚îÄ data_models.py              # Pydantic Schemas (The Contracts)
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py             # Main Workflow Coordinator
‚îÇ   ‚îú‚îÄ‚îÄ pdf_generator.py            # ReportLab PDF Engine
‚îÇ   ‚îú‚îÄ‚îÄ questionnaire.py            # Static Interview Questions
‚îÇ   ‚îî‚îÄ‚îÄ workflow_state.py           # Finite State Machine
‚îÇ
‚îú‚îÄ‚îÄ demos/                          # Interactive Playground scripts
‚îÇ   ‚îú‚îÄ‚îÄ demo_problem_formulation.py
‚îÇ   ‚îú‚îÄ‚îÄ demo_orchestrator.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ deployment/                     # Cloud Run / Docker config
‚îú‚îÄ‚îÄ docs/                           # Technical Documentation
‚îÇ   ‚îú‚îÄ‚îÄ AGENT-GUIDE.md
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îÇ   ‚îî‚îÄ‚îÄ DATA-FLOW.md
‚îÇ
‚îú‚îÄ‚îÄ eval/                           # Evaluation Framework
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Test Scenarios
‚îÇ   ‚îî‚îÄ‚îÄ test_multi_agent_pipeline.py
‚îÇ
‚îú‚îÄ‚îÄ tests/                          # Unit Tests
‚îú‚îÄ‚îÄ .env                            # Credentials (GitIgnored)
‚îú‚îÄ‚îÄ app.py                          # Streamlit Entry Point
‚îú‚îÄ‚îÄ run_interactive_demo.py         # CLI Entry Point
‚îú‚îÄ‚îÄ README.md                       # Main Project documentation
‚îî‚îÄ‚îÄ pyproject.toml                  # Dependencies
```



## Testing & Evaluation

### Unit Tests
Run the comprehensive test suite using `pytest` to verify individual agent logic and regex parsers.

```bash
uv run pytest tests/
```

### End-to-End Evaluation
Run integration scenarios to validate the full pipeline against specific research topics.

```bash
# Run the pipeline test script
python eval/test_multi_agent_pipeline.py
```


## Deployment

>Deploy to Cloud Run: follow instructions in [deployment directory](deployment/README.md)


## Documentation

For detailed technical specifications, please refer to the `docs/` folder:

- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)**: High-level design, State Machine diagrams, and Orchestrator logic.
- **[DATA-FLOW.md](docs/DATA-FLOW.md)**: Detailed mapping of Inputs/Outputs per agent and Pydantic schemas.
- **[AGENT-GUIDE.md](docs/AGENT-GUIDE.md)**: Specific prompt strategies and logic for each sub-agent.
